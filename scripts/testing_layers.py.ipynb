{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d83b7394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently Loaded Modulefiles:\n",
      " 1) rvs-cloud/1.0   2) anaconda/3/2023.03  \n"
     ]
    }
   ],
   "source": [
    "module(\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49b42209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pytorch/gpu-cuda-11.6/2.1.0\n",
      "  Loading requirement: cuda/11.6 cudnn/8.9.2\n"
     ]
    }
   ],
   "source": [
    "module(\"load\",\"pytorch/gpu-cuda-11.6/2.1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e5aec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tensorflow/gpu-cuda-11.6/2.13.0\n",
      "  Loading requirement: protobuf/4.24.0 nccl/2.18.3 tensorrt/8.6.1\n"
     ]
    }
   ],
   "source": [
    "module(\"load\",\"tensorflow/gpu-cuda-11.6/2.13.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de86c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "module(\"load\",\"keras/2.13.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f0c56b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently Loaded Modulefiles:\n",
      " 1) rvs-cloud/1.0                 6) protobuf/4.24.0 <aL>             \n",
      " 2) anaconda/3/2023.03            7) nccl/2.18.3 <aL>                 \n",
      " 3) cuda/11.6 <aL>                8) tensorrt/8.6.1 <aL>              \n",
      " 4) cudnn/8.9.2 <aL>              9) tensorflow/gpu-cuda-11.6/2.13.0  \n",
      " 5) pytorch/gpu-cuda-11.6/2.1.0  10) keras/2.13.1                     \n",
      "\n",
      "Key:\n",
      "<module-tag>  <aL>=auto-loaded  \n"
     ]
    }
   ],
   "source": [
    "module(\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "586ffa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload  #Reloads updated modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76e9f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fe6c6d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Import TensorFlow classes\n",
    "#from layers import StochasticDepth as TFStochasticDepth, RandomDrop as TFRandomDrop\n",
    "\n",
    "# Import PyTorch classes\n",
    "#from layers_pytorch import StochasticDepth as PTStochasticDepth, RandomDrop as PTRandomDrop\n",
    "\n",
    "from layers import StochasticDepth as TFStochasticDepth, RandomDrop as TFRandomDrop, SimpleHeadAttention as TFSimpleHeadAttention, TalkingHeadAttention as TFTalkingHeadAttention, LayerScale as TFLayerScale\n",
    "from layers_pytorch import StochasticDepth as PTStochasticDepth, RandomDrop as PTRandomDrop, SimpleHeadAttention as PTSimpleHeadAttention, TalkingHeadAttention as PTTalkingHeadAttention, LayerScale as PTLayerScale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a7367249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create a random input tensor\n",
    "batch_size, seq_len, num_features = 32, 10, 64\n",
    "np_input = np.random.randn(batch_size, seq_len, num_features).astype(np.float32)\n",
    "\n",
    "# Create TensorFlow tensor\n",
    "tf_input = tf.convert_to_tensor(np_input)\n",
    "\n",
    "# Create PyTorch tensor\n",
    "pt_input = torch.from_numpy(np_input)\n",
    "\n",
    "# Modify StochasticDepth classes to accept the random tensor\n",
    "class TFStochasticDepthModified(TFStochasticDepth):\n",
    "    def call(self, x, random_tensor, training=False):\n",
    "        if training:\n",
    "            keep_prob = 1 - self.drop_prob\n",
    "            random_tensor = keep_prob + random_tensor\n",
    "            random_tensor = tf.floor(random_tensor)\n",
    "            x = x * random_tensor\n",
    "            return x \n",
    "        return x\n",
    "\n",
    "class PTStochasticDepthModified(PTStochasticDepth):\n",
    "    def forward(self, x, random_tensor, training=False):\n",
    "        if training:\n",
    "            keep_prob = 1 - self.drop_prob\n",
    "            random_tensor = keep_prob + random_tensor\n",
    "            random_tensor = torch.floor(random_tensor)\n",
    "            x = x * random_tensor\n",
    "            return x\n",
    "        return x\n",
    "\n",
    "\n",
    "# Parameters\n",
    "drop_prob = 0.1\n",
    "num_skip = 5\n",
    "\n",
    "# TensorFlow layers\n",
    "tf_stochastic_depth = TFStochasticDepth(drop_prob)\n",
    "tf_random_drop = TFRandomDrop(drop_prob, num_skip)\n",
    "\n",
    "# PyTorch layers\n",
    "pt_stochastic_depth = PTStochasticDepth(drop_prob)\n",
    "pt_random_drop = PTRandomDrop(drop_prob, num_skip)\n",
    "\n",
    "# Modified StochasticDepth\n",
    "tf_stochastic_depth_m = TFStochasticDepthModified(drop_prob)\n",
    "pt_stochastic_depth_m = PTStochasticDepthModified(drop_prob)\n",
    "\n",
    "# TensorFlow forward pass\n",
    "tf_stochastic_output = tf_stochastic_depth(tf_input, training=True)\n",
    "tf_random_drop_output = tf_random_drop(tf_input, training=True)\n",
    "\n",
    "# PyTorch forward pass\n",
    "pt_stochastic_output = pt_stochastic_depth(pt_input, training=True)\n",
    "pt_random_drop_output = pt_random_drop(pt_input, training=True)\n",
    "\n",
    "# Forward pass of modified StochasticDepth\n",
    "np_random = np.random.rand(batch_size, 1, 1).astype(np.float32)\n",
    "tf_random = tf.convert_to_tensor(np_random)\n",
    "pt_random = torch.from_numpy(np_random)\n",
    "\n",
    "tf_output = tf_stochastic_depth_m(tf_input, tf_random, training=True)\n",
    "pt_output = pt_stochastic_depth_m(pt_input, pt_random, training=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7f4ec657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing StochasticDepth with common random number:\n",
      "  Shape: TF (32, 10, 64), PT (32, 10, 64)\n",
      "  Mean: TF -0.000701, PT -0.000701\n",
      "  Std: TF 0.902680, PT 0.902680\n",
      "  Max Abs Diff: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Convert outputs to numpy for comparison\n",
    "tf_output_np = tf_output.numpy()\n",
    "pt_output_np = pt_output.detach().numpy()\n",
    "\n",
    "# Compare outputs\n",
    "print(\"Comparing StochasticDepth with common random number:\")\n",
    "print(f\"  Shape: TF {tf_output_np.shape}, PT {pt_output_np.shape}\")\n",
    "print(f\"  Mean: TF {tf_output_np.mean():.6f}, PT {pt_output_np.mean():.6f}\")\n",
    "print(f\"  Std: TF {tf_output_np.std():.6f}, PT {pt_output_np.std():.6f}\")\n",
    "print(f\"  Max Abs Diff: {np.abs(tf_output_np - pt_output_np).max():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dab6810e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing StochasticDepth:\n",
      "  Shape: TF (32, 10, 64), PT (32, 10, 64)\n",
      "  Mean: TF 0.005732, PT 0.007001\n",
      "  Std: TF 0.972660, PT 0.969924\n",
      "  Max Abs Diff: 3.942331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert outputs to numpy for comparison\n",
    "tf_stochastic_np = tf_stochastic_output.numpy()\n",
    "tf_random_drop_np = tf_random_drop_output.numpy()\n",
    "pt_stochastic_np = pt_stochastic_output.detach().numpy()\n",
    "pt_random_drop_np = pt_random_drop_output.detach().numpy()\n",
    "\n",
    "# Compare outputs when rnadom number is not common for both functions\n",
    "\n",
    "print(f\"Comparing StochasticDepth:\")\n",
    "print(f\"  Shape: TF {tf_stochastic_np.shape}, PT {pt_stochastic_np.shape}\")\n",
    "print(f\"  Mean: TF {tf_stochastic_np.mean():.6f}, PT {pt_stochastic_np.mean():.6f}\")\n",
    "print(f\"  Std: TF {tf_stochastic_np.std():.6f}, PT {pt_stochastic_np.std():.6f}\")\n",
    "print(f\"  Max Abs Diff: {np.abs(tf_stochastic_np - pt_stochastic_np).max():.6f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3ca73553",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, seq_len, num_features = 32, 10, 64\n",
    "np_input = np.random.randn(batch_size, seq_len, num_features).astype(np.float32)\n",
    "\n",
    "# Create TensorFlow and PyTorch input tensors\n",
    "pt_input = torch.from_numpy(np_input)\n",
    "\n",
    "np_random = np.random.rand(batch_size, 1,1).astype(np.float32)\n",
    "pt_random = torch.from_numpy(np_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d6d860b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 1, 1])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_random.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9afec294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 64])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b9fdc317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1]) torch.Size([32, 10, 64])\n",
      "torch.Size([32, 1, 1])\n",
      "torch.Size([32, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "shape = (pt_input.size(0), 1)\n",
    "pt_random = torch.reshape(pt_random, shape)\n",
    "print(pt_random.shape, pt_input.shape)\n",
    "pt_input[:,:,5:] = pt_input[:,:,5:]*pt_random.unsqueeze(-1)\n",
    "print(pt_random.unsqueeze(-1).shape)\n",
    "print(final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fff6e7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing RandomDrop:\n",
      "  Shape: TF (32, 10, 64), PT (32, 10, 64)\n",
      "  Mean: TF -0.001324, PT -0.001324\n",
      "  Std: TF 0.911613, PT 0.911613\n",
      "  Max Abs Diff: 0.000000\n",
      "\n",
      "Checking if first 'num_skip' features are unchanged:\n",
      "  First 5 features unchanged: True\n",
      "\n",
      "Checking if dropped features are consistent:\n",
      "  Dropped features consistent between TF and PT: True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from layers import RandomDrop as TFRandomDrop\n",
    "from layers_pytorch import RandomDrop as PTRandomDrop\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a random input tensor\n",
    "batch_size, seq_len, num_features = 32, 10, 64\n",
    "np_input = np.random.randn(batch_size, seq_len, num_features).astype(np.float32)\n",
    "\n",
    "# Create TensorFlow and PyTorch input tensors\n",
    "tf_input = tf.convert_to_tensor(np_input)\n",
    "pt_input = torch.from_numpy(np_input)\n",
    "\n",
    "# Parameters\n",
    "drop_prob = 0.1\n",
    "num_skip = 5\n",
    "\n",
    "# Generate a common random tensor for both implementations\n",
    "np_random = np.random.rand(batch_size, 1,1).astype(np.float32)\n",
    "tf_random = tf.convert_to_tensor(np_random)\n",
    "pt_random = torch.from_numpy(np_random)\n",
    "\n",
    "# Modify RandomDrop classes to accept the random tensor\n",
    "class TFRandomDropModified(TFRandomDrop):\n",
    "    def call(self, x, random_tensor, training=False):\n",
    "        if training:\n",
    "            keep_prob = 1 - self.drop_prob\n",
    "            shape = (tf.shape(x)[0], 1, 1)\n",
    "            random_tensor = keep_prob + random_tensor\n",
    "            random_tensor = tf.floor(random_tensor)\n",
    "            \n",
    "            # Create a mask tensor\n",
    "            mask = tf.concat([\n",
    "                tf.ones((tf.shape(x)[0], tf.shape(x)[1], self.num_skip)),\n",
    "                tf.tile(random_tensor, \n",
    "                        [1, tf.shape(x)[1], tf.shape(x)[2] - self.num_skip])\n",
    "            ], axis=2)\n",
    "            \n",
    "            # Apply the mask\n",
    "        return x * mask\n",
    "\n",
    "class PTRandomDropModified(PTRandomDrop):\n",
    "    def forward(self, x, random_tensor, training=False):\n",
    "        if training:\n",
    "            keep_prob = 1 - self.drop_prob\n",
    "            shape = (x.size(0), 1)\n",
    "            random_tensor = torch.reshape(random_tensor, shape)\n",
    "            random_tensor = keep_prob + random_tensor\n",
    "            random_tensor = torch.floor(random_tensor)\n",
    "            x[:, :, self.num_skip:] = x[:, :, self.num_skip:] * random_tensor.unsqueeze(-1)\n",
    "        return x\n",
    "\n",
    "# Create modified layers\n",
    "tf_random_drop = TFRandomDropModified(drop_prob, num_skip)\n",
    "pt_random_drop = PTRandomDropModified(drop_prob, num_skip)\n",
    "\n",
    "# Forward pass\n",
    "tf_output = tf_random_drop(tf_input, tf_random, training=True)\n",
    "pt_output = pt_random_drop(pt_input, pt_random, training=True)\n",
    "\n",
    "# Convert outputs to numpy for comparison\n",
    "tf_output_np = tf_output.numpy()\n",
    "pt_output_np = pt_output.detach().numpy()\n",
    "\n",
    "# Compare outputs\n",
    "print(\"Comparing RandomDrop:\")\n",
    "print(f\"  Shape: TF {tf_output_np.shape}, PT {pt_output_np.shape}\")\n",
    "print(f\"  Mean: TF {tf_output_np.mean():.6f}, PT {pt_output_np.mean():.6f}\")\n",
    "print(f\"  Std: TF {tf_output_np.std():.6f}, PT {pt_output_np.std():.6f}\")\n",
    "print(f\"  Max Abs Diff: {np.abs(tf_output_np - pt_output_np).max():.6f}\")\n",
    "\n",
    "# Additional checks\n",
    "print(\"\\nChecking if first 'num_skip' features are unchanged:\")\n",
    "first_features_unchanged = np.allclose(tf_output_np[:,:,:num_skip], np_input[:,:,:num_skip]) and \\\n",
    "                           np.allclose(pt_output_np[:,:,:num_skip], np_input[:,:,:num_skip])\n",
    "print(f\"  First {num_skip} features unchanged: {first_features_unchanged}\")\n",
    "\n",
    "print(\"\\nChecking if dropped features are consistent:\")\n",
    "dropped_features_consistent = np.allclose(tf_output_np[:,:,num_skip:], pt_output_np[:,:,num_skip:])\n",
    "print(f\"  Dropped features consistent between TF and PT: {dropped_features_consistent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f7612593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow weight shapes:\n",
      "  Weight 0: (64, 192)\n",
      "  Weight 1: (192,)\n",
      "  Weight 2: (64, 64)\n",
      "  Weight 3: (64,)\n",
      "\n",
      "Comparing SimpleHeadAttention outputs:\n",
      "  Shape: TF (4, 10, 64), PT (4, 10, 64)\n",
      "  Mean: TF 0.009182, PT 0.010976\n",
      "  Std: TF 0.250162, PT 0.249307\n",
      "  Max Abs Diff: 0.831630\n",
      "\n",
      "Comparing attention weights:\n",
      "  Shape: TF (4, 4, 10, 10), PT (4, 4, 10, 10)\n",
      "  Mean: TF 0.100000, PT 0.100000\n",
      "  Std: TF 0.046986, PT 0.046986\n",
      "  Max Abs Diff: 0.000000\n",
      "\n",
      "Checking if attention weights sum to 1 for each query:\n",
      "  TF attention weights sum to 1: True\n",
      "  PT attention weights sum to 1: True\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Parameters\n",
    "batch_size = 4\n",
    "seq_len = 10\n",
    "embedding_dim = 64\n",
    "num_heads = 4\n",
    "dropout_rate = 0.1\n",
    "\n",
    "# Create a random input tensor\n",
    "np_input = np.random.randn(batch_size, seq_len, embedding_dim).astype(np.float32)\n",
    "\n",
    "# Create TensorFlow and PyTorch input tensors\n",
    "tf_input = tf.convert_to_tensor(np_input)\n",
    "pt_input = torch.from_numpy(np_input)\n",
    "\n",
    "# Create layers\n",
    "tf_attention = TFSimpleHeadAttention(projection_dim=embedding_dim, num_heads=num_heads, dropout_rate=dropout_rate)\n",
    "pt_attention = PTSimpleHeadAttention(projection_dim=embedding_dim, num_heads=num_heads, dropout_rate=dropout_rate)\n",
    "\n",
    "# Build the TensorFlow layer\n",
    "_ = tf_attention(tf_input)  # This call builds the layer and initializes weights\n",
    "\n",
    "# Get TensorFlow weights\n",
    "tf_weights = tf_attention.get_weights()\n",
    "\n",
    "# Print weight shapes for debugging\n",
    "print(\"TensorFlow weight shapes:\")\n",
    "for i, w in enumerate(tf_weights):\n",
    "    print(f\"  Weight {i}: {w.shape}\")\n",
    "\n",
    "# Ensure the same initial weights for both implementations\n",
    "# For PyTorch\n",
    "pt_attention.qkv.weight.data = torch.from_numpy(tf_weights[0].T)\n",
    "pt_attention.qkv.bias.data = torch.from_numpy(tf_weights[1])\n",
    "pt_attention.proj.weight.data = torch.from_numpy(tf_weights[2].T)\n",
    "pt_attention.proj.bias.data = torch.from_numpy(tf_weights[3])\n",
    "\n",
    "# Forward pass\n",
    "tf_output, tf_attention_weights = tf_attention(tf_input, training=True)\n",
    "pt_output, pt_attention_weights = pt_attention(pt_input, training=True)\n",
    "\n",
    "# Convert outputs to numpy for comparison\n",
    "tf_output_np = tf_output.numpy()\n",
    "pt_output_np = pt_output.detach().numpy()\n",
    "tf_attention_weights_np = tf_attention_weights.numpy()\n",
    "pt_attention_weights_np = pt_attention_weights.detach().numpy()\n",
    "\n",
    "# Compare outputs\n",
    "print(\"\\nComparing SimpleHeadAttention outputs:\")\n",
    "print(f\"  Shape: TF {tf_output_np.shape}, PT {pt_output_np.shape}\")\n",
    "print(f\"  Mean: TF {tf_output_np.mean():.6f}, PT {pt_output_np.mean():.6f}\")\n",
    "print(f\"  Std: TF {tf_output_np.std():.6f}, PT {pt_output_np.std():.6f}\")\n",
    "print(f\"  Max Abs Diff: {np.abs(tf_output_np - pt_output_np).max():.6f}\")\n",
    "\n",
    "# Compare attention weights\n",
    "print(\"\\nComparing attention weights:\")\n",
    "print(f\"  Shape: TF {tf_attention_weights_np.shape}, PT {pt_attention_weights_np.shape}\")\n",
    "print(f\"  Mean: TF {tf_attention_weights_np.mean():.6f}, PT {pt_attention_weights_np.mean():.6f}\")\n",
    "print(f\"  Std: TF {tf_attention_weights_np.std():.6f}, PT {pt_attention_weights_np.std():.6f}\")\n",
    "print(f\"  Max Abs Diff: {np.abs(tf_attention_weights_np - pt_attention_weights_np).max():.6f}\")\n",
    "\n",
    "# Additional check for attention weight normalization\n",
    "print(\"\\nChecking if attention weights sum to 1 for each query:\")\n",
    "tf_sum_to_one = np.allclose(tf_attention_weights_np.sum(axis=-1), 1.0, atol=1e-5)\n",
    "pt_sum_to_one = np.allclose(pt_attention_weights_np.sum(axis=-1), 1.0, atol=1e-5)\n",
    "print(f\"  TF attention weights sum to 1: {tf_sum_to_one}\")\n",
    "print(f\"  PT attention weights sum to 1: {pt_sum_to_one}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a974e9db",
   "metadata": {},
   "source": [
    "# Change layer_pytorch TalkingHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ba56aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class TalkingHeadAttention2(nn.Module):\n",
    "    def __init__(self, projection_dim: int, num_heads: int, dropout_rate: float):\n",
    "        super(TalkingHeadAttention2, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.projection_dim = projection_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        head_dim = self.projection_dim // self.num_heads\n",
    "        self.scale = head_dim**-0.5\n",
    "        self.qkv = nn.Linear(projection_dim, projection_dim * 3)\n",
    "        self.attn_drop = nn.Dropout(dropout_rate)\n",
    "        self.proj = nn.Linear(projection_dim, projection_dim)\n",
    "        self.proj_l = nn.Linear(num_heads, num_heads)\n",
    "        self.proj_w = nn.Linear(num_heads, num_heads)\n",
    "        self.proj_drop = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, int_matrix=None, mask=None, training=False):\n",
    "        B, N, C = x.size()\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0] * self.scale, qkv[1], qkv[2]\n",
    "\n",
    "        attn = torch.matmul(q, k.transpose(-2, -1))\n",
    "        if int_matrix is not None:\n",
    "            attn += int_matrix\n",
    "\n",
    "        # Apply proj_l before softmax\n",
    "        attn = self.proj_l(attn.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
    "        \n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1).repeat(1, self.num_heads, 1, 1)\n",
    "            attn += (1.0 - mask) * -1e9\n",
    "\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        \n",
    "        # Apply proj_w after softmax\n",
    "        attn = self.proj_w(attn.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
    "        attn = self.attn_drop(attn) if training else attn\n",
    "\n",
    "        x = torch.matmul(attn, v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x) if training else x\n",
    "        return x, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1476f345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow weight shapes:\n",
      "  Weight 0: (64, 192)\n",
      "  Weight 1: (192,)\n",
      "  Weight 2: (64, 64)\n",
      "  Weight 3: (64,)\n",
      "  Weight 4: (4, 4)\n",
      "  Weight 5: (4,)\n",
      "  Weight 6: (4, 4)\n",
      "  Weight 7: (4,)\n",
      "\n",
      "Comparing TalkingHeadAttention outputs:\n",
      "  Shape: TF (4, 10, 64), PT (4, 10, 64)\n",
      "  Mean: TF 0.006148, PT 0.001263\n",
      "  Std: TF 0.322211, PT 0.319002\n",
      "  Max Abs Diff: 1.083274\n",
      "\n",
      "Comparing attention weights:\n",
      "  Shape: TF (4, 4, 10, 10), PT (4, 4, 10, 10)\n",
      "  Mean: TF -0.064353, PT -0.062686\n",
      "  Std: TF 0.116113, PT 0.114994\n",
      "  Max Abs Diff: 0.605686\n",
      "\n",
      "Checking if attention weights sum to 1 for each query:\n",
      "  TF attention weights sum to 1: False\n",
      "  PT attention weights sum to 1: False\n"
     ]
    }
   ],
   "source": [
    "from layers import TalkingHeadAttention as TFTalkingHeadAttention\n",
    "\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Parameters\n",
    "batch_size = 4\n",
    "seq_len = 10\n",
    "embedding_dim = 64\n",
    "num_heads = 4\n",
    "dropout_rate = 0.1\n",
    "\n",
    "# Create a random input tensor\n",
    "np_input = np.random.randn(batch_size, seq_len, embedding_dim).astype(np.float32)\n",
    "\n",
    "# Create TensorFlow and PyTorch input tensors\n",
    "tf_input = tf.convert_to_tensor(np_input)\n",
    "pt_input = torch.from_numpy(np_input)\n",
    "\n",
    "# Create layers\n",
    "tf_attention = TFTalkingHeadAttention(projection_dim=embedding_dim, num_heads=num_heads, dropout_rate=dropout_rate)\n",
    "pt_attention = TalkingHeadAttention2(projection_dim=embedding_dim, num_heads=num_heads, dropout_rate=dropout_rate)\n",
    "\n",
    "# Build the TensorFlow layer\n",
    "_ = tf_attention(tf_input)  # This call builds the layer and initializes weights\n",
    "\n",
    "# Get TensorFlow weights\n",
    "tf_weights = tf_attention.get_weights()\n",
    "\n",
    "# Print weight shapes for debugging\n",
    "print(\"TensorFlow weight shapes:\")\n",
    "for i, w in enumerate(tf_weights):\n",
    "    print(f\"  Weight {i}: {w.shape}\")\n",
    "\n",
    "# Ensure the same initial weights for both implementations\n",
    "# For PyTorch\n",
    "pt_attention.qkv.weight.data = torch.from_numpy(tf_weights[0].T)\n",
    "pt_attention.qkv.bias.data = torch.from_numpy(tf_weights[1])\n",
    "pt_attention.proj.weight.data = torch.from_numpy(tf_weights[2].T)\n",
    "pt_attention.proj.bias.data = torch.from_numpy(tf_weights[3])\n",
    "pt_attention.proj_l.weight.data = torch.from_numpy(tf_weights[4].T)\n",
    "pt_attention.proj_l.bias.data = torch.from_numpy(tf_weights[5])\n",
    "pt_attention.proj_w.weight.data = torch.from_numpy(tf_weights[6].T)\n",
    "pt_attention.proj_w.bias.data = torch.from_numpy(tf_weights[7])\n",
    "\n",
    "# Forward pass\n",
    "tf_output, tf_attention_weights = tf_attention(tf_input, training=True)\n",
    "pt_output, pt_attention_weights = pt_attention(pt_input, training=True)\n",
    "\n",
    "# Convert outputs to numpy for comparison\n",
    "tf_output_np = tf_output.numpy()\n",
    "pt_output_np = pt_output.detach().numpy()\n",
    "tf_attention_weights_np = tf_attention_weights.numpy()\n",
    "pt_attention_weights_np = pt_attention_weights.detach().numpy()\n",
    "\n",
    "# Compare outputs\n",
    "print(\"\\nComparing TalkingHeadAttention outputs:\")\n",
    "print(f\"  Shape: TF {tf_output_np.shape}, PT {pt_output_np.shape}\")\n",
    "print(f\"  Mean: TF {tf_output_np.mean():.6f}, PT {pt_output_np.mean():.6f}\")\n",
    "print(f\"  Std: TF {tf_output_np.std():.6f}, PT {pt_output_np.std():.6f}\")\n",
    "print(f\"  Max Abs Diff: {np.abs(tf_output_np - pt_output_np).max():.6f}\")\n",
    "\n",
    "# Compare attention weights\n",
    "print(\"\\nComparing attention weights:\")\n",
    "print(f\"  Shape: TF {tf_attention_weights_np.shape}, PT {pt_attention_weights_np.shape}\")\n",
    "print(f\"  Mean: TF {tf_attention_weights_np.mean():.6f}, PT {pt_attention_weights_np.mean():.6f}\")\n",
    "print(f\"  Std: TF {tf_attention_weights_np.std():.6f}, PT {pt_attention_weights_np.std():.6f}\")\n",
    "print(f\"  Max Abs Diff: {np.abs(tf_attention_weights_np - pt_attention_weights_np).max():.6f}\")\n",
    "\n",
    "# Additional check for attention weight normalization\n",
    "print(\"\\nChecking if attention weights sum to 1 for each query:\")\n",
    "tf_sum_to_one = np.allclose(tf_attention_weights_np.sum(axis=-1), 1.0, atol=1e-5)\n",
    "pt_sum_to_one = np.allclose(pt_attention_weights_np.sum(axis=-1), 1.0, atol=1e-5)\n",
    "print(f\"  TF attention weights sum to 1: {tf_sum_to_one}\")\n",
    "print(f\"  PT attention weights sum to 1: {pt_sum_to_one}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "db68eb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing StochasticDepth:\n",
      "  Shape: TF (32, 10, 64, 1), PT (32, 10, 64, 1)\n",
      "  Mean: TF 0.005732, PT 0.007001\n",
      "  Std: TF 0.972660, PT 0.969924\n",
      "  Max Abs Diff: 3.942331\n",
      "\n",
      "Comparing RandomDrop:\n",
      "  Shape: TF (32, 10, 64), PT (32, 10, 64)\n",
      "  Mean: TF -0.009080, PT -0.004371\n",
      "  Std: TF 0.981644, PT 0.979563\n",
      "  Max Abs Diff: 4.465604\n",
      "\n",
      "Comparing SimpleHeadAttention_0:\n",
      "  Shape: TF (32, 10, 64), PT (32, 10, 64)\n",
      "  Mean: TF -0.046840, PT -0.006215\n",
      "  Std: TF 0.453468, PT 0.202695\n",
      "  Max Abs Diff: 1.613864\n",
      "\n",
      "Comparing SimpleHeadAttention_1:\n",
      "  Shape: TF (32, 4, 10, 10), PT (32, 4, 10, 10)\n",
      "  Mean: TF 0.100000, PT 0.100000\n",
      "  Std: TF 0.007855, PT 0.005192\n",
      "  Max Abs Diff: 0.038661\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (80x10 and 4x4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 109\u001b[0m\n\u001b[1;32m    107\u001b[0m test_random_drop()\n\u001b[1;32m    108\u001b[0m test_simple_head_attention()\n\u001b[0;32m--> 109\u001b[0m \u001b[43mtest_talking_head_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m test_layer_scale()\n",
      "Cell \u001b[0;32mIn[116], line 85\u001b[0m, in \u001b[0;36mtest_talking_head_attention\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m pt_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x)\n\u001b[1;32m     84\u001b[0m tf_output \u001b[38;5;241m=\u001b[39m tf_layer(tf_input, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 85\u001b[0m pt_output \u001b[38;5;241m=\u001b[39m \u001b[43mpt_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpt_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m compare_outputs(tf_output, pt_output, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTalkingHeadAttention\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/raven/u/phebbar/Work/OmniLearn/OmniLearn/images/omni_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raven/u/phebbar/Work/OmniLearn/OmniLearn/images/omni_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/raven/u/phebbar/Work/OmniLearn/OmniLearn/scripts/layers_pytorch.py:101\u001b[0m, in \u001b[0;36mTalkingHeadAttention.forward\u001b[0;34m(self, x, int_matrix, mask, training)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m int_matrix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     attn \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m int_matrix\n\u001b[0;32m--> 101\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproj_l\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/raven/u/phebbar/Work/OmniLearn/OmniLearn/images/omni_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raven/u/phebbar/Work/OmniLearn/OmniLearn/images/omni_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/raven/u/phebbar/Work/OmniLearn/OmniLearn/images/omni_venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (80x10 and 4x4)"
     ]
    }
   ],
   "source": [
    "#Set random seets\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Helper function to compare TensorFlow and PyTorch outputs\n",
    "def compare_outputs(tf_output, pt_output, name):\n",
    "    tf_output = tf_output.numpy() if isinstance(tf_output, tf.Tensor) else tf_output\n",
    "    pt_output = pt_output.detach().numpy() if isinstance(pt_output, torch.Tensor) else pt_output\n",
    "    \n",
    "    if isinstance(tf_output, tuple):\n",
    "        for i, (tf_item, pt_item) in enumerate(zip(tf_output, pt_output)):\n",
    "            compare_outputs(tf_item, pt_item, f\"{name}_{i}\")\n",
    "    else:\n",
    "        print(f\"Comparing {name}:\")\n",
    "        print(f\"  Shape: TF {tf_output.shape}, PT {pt_output.shape}\")\n",
    "        print(f\"  Mean: TF {tf_output.mean():.6f}, PT {pt_output.mean():.6f}\")\n",
    "        print(f\"  Std: TF {tf_output.std():.6f}, PT {pt_output.std():.6f}\")\n",
    "        print(f\"  Max Abs Diff: {np.abs(tf_output - pt_output).max():.6f}\")\n",
    "        print()\n",
    "\n",
    "# Test StochasticDepth\n",
    "def test_stochastic_depth():\n",
    "    drop_prob = 0.1\n",
    "    tf_layer = TFStochasticDepth(drop_prob)\n",
    "    pt_layer = PTStochasticDepth(drop_prob)\n",
    "    \n",
    "    x = np.random.randn(32, 10, 64, 1).astype(np.float32)\n",
    "    tf_input = tf.constant(x)\n",
    "    pt_input = torch.tensor(x)\n",
    "    \n",
    "    tf_output = tf_layer(tf_input, training=True)\n",
    "    pt_output = pt_layer(pt_input, training=True)\n",
    "    \n",
    "    compare_outputs(tf_output, pt_output, \"StochasticDepth\")\n",
    "\n",
    "# Test RandomDrop\n",
    "def test_random_drop():\n",
    "    drop_prob = 0.1\n",
    "    num_skip = 2\n",
    "    tf_layer = TFRandomDrop(drop_prob, num_skip)\n",
    "    pt_layer = PTRandomDrop(drop_prob, num_skip)\n",
    "    \n",
    "    x = np.random.randn(32, 10, 64).astype(np.float32)\n",
    "    \n",
    "    # Use NumPy array for TensorFlow layer\n",
    "    tf_output = tf_layer(x, training=True).numpy()\n",
    "    \n",
    "    # Use PyTorch tensor for PyTorch layer\n",
    "    pt_input = torch.tensor(x)\n",
    "    pt_output = pt_layer(pt_input, training=True)\n",
    "    \n",
    "    compare_outputs(tf_output, pt_output, \"RandomDrop\")\n",
    "\n",
    "# Test SimpleHeadAttention\n",
    "def test_simple_head_attention():\n",
    "    projection_dim = 64\n",
    "    num_heads = 4\n",
    "    dropout_rate = 0.1\n",
    "    tf_layer = TFSimpleHeadAttention(projection_dim, num_heads, dropout_rate)\n",
    "    pt_layer = PTSimpleHeadAttention(projection_dim, num_heads, dropout_rate)\n",
    "    \n",
    "    x = np.random.rand(32, 10, projection_dim).astype(np.float32)\n",
    "    tf_input = tf.constant(x)\n",
    "    pt_input = torch.tensor(x)\n",
    "    \n",
    "    tf_output = tf_layer(tf_input, training=True)\n",
    "    pt_output = pt_layer(pt_input, training=True)\n",
    "    \n",
    "    compare_outputs(tf_output, pt_output, \"SimpleHeadAttention\")\n",
    "\n",
    "# Test TalkingHeadAttention\n",
    "def test_talking_head_attention():\n",
    "    projection_dim = 64\n",
    "    num_heads = 4\n",
    "    dropout_rate = 0.1\n",
    "    tf_layer = TFTalkingHeadAttention(projection_dim, num_heads, dropout_rate)\n",
    "    pt_layer = PTTalkingHeadAttention(projection_dim, num_heads, dropout_rate)\n",
    "    \n",
    "    x = np.random.rand(2, 10, projection_dim).astype(np.float32)\n",
    "    tf_input = tf.constant(x)\n",
    "    pt_input = torch.tensor(x)\n",
    "    \n",
    "    tf_output = tf_layer(tf_input, training=True)\n",
    "    pt_output = pt_layer(pt_input, training=True)\n",
    "    \n",
    "    compare_outputs(tf_output, pt_output, \"TalkingHeadAttention\")\n",
    "\n",
    "# Test LayerScale\n",
    "def test_layer_scale():\n",
    "    init_values = 0.1\n",
    "    projection_dim = 64\n",
    "    tf_layer = TFLayerScale(init_values, projection_dim)\n",
    "    pt_layer = PTLayerScale(init_values, projection_dim)\n",
    "    \n",
    "    x = np.random.rand(2, 10, projection_dim).astype(np.float32)\n",
    "    tf_input = tf.constant(x)\n",
    "    pt_input = torch.tensor(x)\n",
    "    \n",
    "    tf_output = tf_layer(tf_input)\n",
    "    pt_output = pt_layer(pt_input)\n",
    "    \n",
    "    compare_outputs(tf_output, pt_output, \"LayerScale\")\n",
    "\n",
    "# Run all tests\n",
    "test_stochastic_depth()\n",
    "test_random_drop()\n",
    "test_simple_head_attention()\n",
    "test_talking_head_attention()\n",
    "test_layer_scale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e37c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c890a0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnivenv",
   "language": "python",
   "name": "omnivenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
